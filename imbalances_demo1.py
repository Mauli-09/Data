# -*- coding: utf-8 -*-
"""imbalances_demo1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OvPQbdOf3TZ11MXwBU-CB7W6E0oLyKWB
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("Gender_loan.csv")

print("Dataset shape:", df.shape)
print(df.head())
print(df.info())

df.isnull().sum()

print("\nData Types:\n", df.dtypes)

# --- Step 4: Basic Statistics ---
print("\nDescriptive Statistics:\n", df.describe(include='all'))

# --- Step 5: Check Representation Imbalance ---
print("\nCounts by Gender:\n", df['sex'].value_counts(normalize=True))

sns.countplot(data=df, x='sex')
plt.title("Gender Representation in Dataset")
plt.show()

# Assuming target variable is 'loan_approved' (replace if different)
print("\nLoan Approval Counts:\n", df['bank_loan'].value_counts(normalize=True))
sns.countplot(data=df, x='bank_loan')
plt.title("Loan Approval Distribution")
plt.show()

# Convert 'bank_loan' to numeric: Yes=1, No=0
df['bank_loan_numeric'] = df['bank_loan'].map({'Yes': 1, 'No': 0})

# Group by gender and calculate selection rate (mean of numeric values)
group_metrics = df.groupby('sex')['bank_loan_numeric'].agg(['mean', 'count'])
group_metrics.rename(columns={'mean': 'Selection Rate'}, inplace=True)

print("\nSelection Rate by Gender:\n", group_metrics)

# --- Step 8: Check Approval Rate by Gender ---
sns.barplot(data=df, x='sex', y='bank_loan_numeric', ci=None)
plt.title("Loan Approval Rate by Gender (Selection Rate)")
plt.show()

# --- Step 9: Correlation Analysis ---
numeric_df = df.select_dtypes(include=['int64', 'float64'])
plt.figure(figsize=(10,6))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

# --- Step 10: Fairness Metrics by Gender (based on ground truth) ---

# Ensure 'bank_loan' is numeric: Yes = 1, No = 0
if df['bank_loan'].dtype == 'object':
    df['bank_loan'] = df['bank_loan'].map({'Yes': 1, 'No': 0})

# Dictionary to store metrics for each gender
metrics_by_group = {}

for gender in df['sex'].unique():
    group = df[df['sex'] == gender]

    # --- Fairness-related metrics ---
    selection_rate = group['bank_loan'].mean()  # fraction approved

    # --- Contextual metrics (not fairness, but helps interpret differences) ---
    avg_salary = group['salary'].mean()
    avg_exp = group['years_exp'].mean()
    total_count = len(group)

    metrics_by_group[gender] = {
        'Selection Rate': round(selection_rate, 3),
        'Average Salary': round(avg_salary, 2),
        'Average Experience': round(avg_exp, 2),
        'Count': total_count
    }

# Convert metrics to a DataFrame for clear viewing
fairness_df = pd.DataFrame(metrics_by_group).T

print("\n=== Fairness Summary by Gender ===\n")
print(fairness_df)

'''
uncovered demographic imbalances can lead to algorithmic bias if not mitigated before training models. Hence,
rebalancing techniques (e.g., re-sampling, fairness constraints, or weighted models) should
be considered in subsequent labs such as Fairness Evaluation, Bias Detection, and Model
Explainability.
'''